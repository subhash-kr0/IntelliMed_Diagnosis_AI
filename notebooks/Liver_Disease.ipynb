{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logistic regression model used in the previous example is not necessarily the best model for liver disease prediction. Let me explain how to improve accuracy and suggest better approaches:\n",
    "\n",
    "Why Logistic Regression Might Not Be Best\n",
    "Class imbalance (common in medical datasets)\n",
    "\n",
    "Non-linear relationships between features\n",
    "\n",
    "Feature interactions not captured effectively\n",
    "\n",
    "Dataset-specific characteristics needing specialized handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Better Approaches for Higher Accuracy\n",
    "\n",
    "1. Try Different Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(XGBClassifier(), param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle Class Imbalance\n",
    "# Check class distribution\n",
    "print(y.value_counts())\n",
    "\n",
    "# Solutions\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE()\n",
    "X_res, y_res = smote.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Feature Engineering\n",
    "# Create new features\n",
    "df['Total_Bilirubin_ratio'] = df['Direct_Bilirubin'] / df['Total_Bilirubin']\n",
    "df['Protein_ratio'] = df['Albumin'] / df['Total_Proteins']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-by-Step Improvement Plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "# Handle outliers\n",
    "from scipy import stats\n",
    "df = df[(np.abs(stats.zscore(df[numerical_features])) < 3).all(axis=1)]\n",
    "\n",
    "# Better encoding\n",
    "df = pd.get_dummies(df, columns=['Gender'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "estimators = [\n",
    "    ('xgb', XGBClassifier()),\n",
    "    ('rf', RandomForestClassifier()),\n",
    "    ('svm', SVC(probability=True))\n",
    "]\n",
    "\n",
    "ensemble = VotingClassifier(estimators, voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Critical Enhancements for Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Monitoring\n",
    "# Log metrics with MLflow\n",
    "import mlflow\n",
    "mlflow.log_metric(\"accuracy\", accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance Analysis\n",
    "import shap\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probability Calibration\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "calibrated_model = CalibratedClassifierCV(base_model, method='isotonic', cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deployment Optimization\n",
    "# Convert model to ONNX format\n",
    "from skl2onnx import convert_sklearn\n",
    "onnx_model = convert_sklearn(model, 'liver_model.onnx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to Choose the Best Model\n",
    "Evaluate using precision-recall curves (better than accuracy for imbalanced data)\n",
    "\n",
    "Use Bayesian Optimization for hyperparameter tuning\n",
    "\n",
    "Implement automated feature selection\n",
    "\n",
    "Test multiple evaluation metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
